---
title: "VITATECS: A Diagnostic Dataset for Temporal Concept Understanding of Video-Language Models"
collection: publications
permalink: /publication/vitatecs
excerpt: The ability to perceive how objects change over time is a crucial ingredient in human intelligence. However, current video-language benchmarks cannot faithfully reflect the temporal understanding abilities of the models due to the existence of static visual shortcuts. To remedy this issue, we present VITATECS, a diagnostic <b>VI</b>deo-<b>T</b>ext d<b>A</b>taset for the evaluation of <b>TE</b>mporal <b>C</b>oncept under<b>S</b>tanding. Specifically, we first introduce a fine-grained taxonomy of temporal concepts in natural language in order to diagnose the capability of video-language models to comprehend different temporal aspects. Furthermore, to disentangle the correlation between static and temporal information, we generate counterfactual video descriptions that differ from the original one only in the specified temporal aspect. We further propose a semi-automatic data collection framework using large language models and human-in-the-loop annotation to obtain high-quality counterfactual descriptions efficiently. Evaluation of representative video-language understanding models confirms their deficiency in temporal understanding, revealing the need for greater emphasis on the temporal elements in video-language research. 
paperurl: 'https://arxiv.org/abs/2311.17404'
projecturl: 'https://github.com/lscpku/VITATECS'
dataurl: 'https://huggingface.co/datasets/lscpku/VITATECS'
authors: '<b>Shicheng Li</b>, Lei Li, Shuhuai Ren, Yuanxin Liu, Yi Liu, Rundong Gao, Xu Sun, Lu Hou'
---
